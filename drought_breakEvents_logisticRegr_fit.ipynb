{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b79301-0cb1-4daa-826a-4050d9dd71d0",
   "metadata": {},
   "source": [
    "### Fit logistic regression to responses against predictors for selected sample grids\n",
    "\n",
    "#### Data used\n",
    "\n",
    "- Predictands: gridded precipitation data (AGCD v1), gridded evapotranspiration and runoff data (AWRA)\n",
    "- Predictors: season, climate drivers (ENSO, IOD, and SAM, these could be categorical or quantitative)\n",
    "\n",
    "#### Code fits the model to data at various time scales and thresholds, and creates summary plots to visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcee17ca-bc53-41d7-8a3b-2ec27cfc5ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e38d7ae-2309-4db9-96a1-910ea4127ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9d03ab4-6440-4644-8925-abfd069e438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting logistic regression models to test grid points\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "# model = glm(formula, data, family)\n",
    "\n",
    "out_dir = '/g/data/w97/ad9701/p_prob_analysis/temp_files/'\n",
    "\n",
    "varname = 'PminusEQ' #'P'   # the name of the directory and file\n",
    "vname = 'PminusEQ' #'precip'  # the name of the variable inside the files\n",
    "fname = varname + '_*_SEA_*.nc'\n",
    "\n",
    "# select some thresholds to look at\n",
    "threshList = [50, 100, 150]\n",
    "\n",
    "# select some lat-lons to look at\n",
    "latList = [-34] #, -34, -34, -37, -37, -37]\n",
    "lonList = [148] #, 145, 142, 148, 145, 142]\n",
    "\n",
    "# select some timescales for analysis\n",
    "ts = [2] #, 6, 8, 12]\n",
    "\n",
    "# get the sst predictors\n",
    "sst_dir = '/g/data/w97/ad9701/p_prob_analysis/sst_data/'\n",
    "pNames = ['soi', 'sami', 'dmi', 'nino34_anom', 'nino4_anom']\n",
    "pFiles = ['soi_monthly.nc', 'newsam.1957.2021.nc', 'dmi.had.long.data.nc', 'nino34.long.anom.data.nc', 'nino4.long.anom.data.nc']\n",
    "for p in np.arange(len(pNames)):\n",
    "    ds_temp = xr.open_dataset(sst_dir+pFiles[p])\n",
    "    if (p>0):\n",
    "        ds_p[pNames[p]]=ds_temp[pNames[p]]\n",
    "    else:\n",
    "        ds_p = ds_temp\n",
    "    del ds_temp\n",
    "\n",
    "# select the predictors to include in the model\n",
    "predSel = ['season', 'soi', 'dmi']\n",
    "formula = 'response ~ C(season)+soi+dmi'\n",
    "    \n",
    "# function to create a new data frame that will be used to 'predict' probabilities from the fitted model\n",
    "# the new data points would cover combinations of unique values for categorical predictors and mean/perturbations one sd above the mean for quantitative predictors\n",
    "import itertools\n",
    "import pandas as pd\n",
    "def createNewDf(df, fields):\n",
    "    '''Function creates a sample dataframe from a larger input dataframe (df).\n",
    "       The sample points will include all permutations of columns specfied (fields).\n",
    "       String columns: use unique values. Numeric columns: Mean, Mean-1SD, Mean+1SD\n",
    "    '''\n",
    "    dataVal = []\n",
    "    for f in fields:\n",
    "        # str data types are assumed to be categorical variables\n",
    "        if (isinstance(df[f][0], str)):\n",
    "            dataVal.append(pd.unique(df[f]))\n",
    "        else:\n",
    "            temp = [df[f].mean()]\n",
    "            temp.extend([df[f].mean()+df[f].std(), df[f].mean()-df[f].std()])\n",
    "            dataVal.append(temp)\n",
    "            del temp\n",
    "    # get all combinations of values across the fields\n",
    "    dataValPermute = list(itertools.product(*dataVal))\n",
    "    # make it into a data frame\n",
    "    newDf = pd.DataFrame(dataValPermute, columns = fields)\n",
    "    return(newDf)\n",
    "\n",
    "def addLatLonTh(mydict, latSel, lonSel, threshSel):\n",
    "    mydict.update({'lat':latSel})\n",
    "    mydict.update({'lon':lonSel})\n",
    "    mydict.update({'threshold':threshSel})\n",
    "    return(mydict)\n",
    "\n",
    "def addLatLonThTimeDf(df, latSel, lonSel, threshSel, tsSel):\n",
    "    df['lat'] = latSel\n",
    "    df['lon'] = lonSel\n",
    "    df['threshold'] = threshSel\n",
    "    df['timescale'] = tsSel\n",
    "    return(df)\n",
    "\n",
    "lgR_params_list = []\n",
    "lgR_pvalues_list = []\n",
    "lgR_pred_list = []\n",
    "lgR_aic_list = []\n",
    "\n",
    "for iW in ts:\n",
    "    data_dir = '/g/data/w97/ad9701/p_prob_analysis/temp_files/'+varname+'_week'+str(iW)+'/'\n",
    "    ds = xr.open_mfdataset(data_dir + fname, chunks = {'lat':400, 'lon':400})\n",
    "    \n",
    "    # select predictors for the same period as the data\n",
    "    x1 = ds['time.season'].values     # season, this is the first predictor\n",
    "    da_time_bymon = np.array(pd.to_datetime(ds.time).to_period('M').to_timestamp().floor('D'))\n",
    "    ds_p_sel = ds_p.sel(time = da_time_bymon)\n",
    "    xp = []\n",
    "    for p in pNames:\n",
    "        xp.append(ds_p_sel[p].values)\n",
    "    xp_dict = dict(zip(pNames, xp))\n",
    "    xp_dict.update({\"season\": x1})    # add season to the sst predictors    \n",
    "    xp_df = pd.DataFrame(xp_dict)     # make a dataframe of predictors\n",
    "    \n",
    "    # create a new df of sample points at which 'predictions' will be made using the fitted model\n",
    "    newDf = createNewDf(xp_df, predSel)\n",
    "    \n",
    "    lgR_params = {}\n",
    "    lgR_pvalues = {}\n",
    "    lgR_pred = {}\n",
    "    lgR_aic = {}\n",
    "    \n",
    "    for iPt in np.arange(len(latList)):\n",
    "        latSel = latList[iPt]\n",
    "        lonSel = lonList[iPt]\n",
    "        da_pt = ds[vname].sel(lat = latSel, lon = lonSel).load()\n",
    "\n",
    "        for ith in np.arange(len(threshList)):\n",
    "            # field name to save the results\n",
    "            field = 'p'+str(iPt)+'_th'+str(ith)\n",
    "            \n",
    "            # create a dataframe of reponse and predictors\n",
    "            y = np.where(da_pt.values>=threshList[ith], 1, 0)\n",
    "            d = {\"response\": y}\n",
    "            if (sum(y)<4):\n",
    "                p_pred = newDf.copy()\n",
    "                p_pred['prob'] = 0\n",
    "                lgR_params.update({field:np.nan})\n",
    "                lgR_pvalues.update({field:np.nan})  \n",
    "                lgR_aic.update({field:np.nan})\n",
    "            else:\n",
    "                d.update(xp_dict)\n",
    "                df = pd.DataFrame(d)\n",
    "\n",
    "                # fit the regression model\n",
    "                model = glm(formula, df, family=sm.families.Binomial())\n",
    "                model_GLM = model.fit()\n",
    "                p_pred = newDf.copy()\n",
    "                prob = model_GLM.predict(newDf)\n",
    "                p_pred['prob'] = prob\n",
    "\n",
    "                # save the results\n",
    "                GLM_params = addLatLonThTimeDf(model_GLM.params, latSel, lonSel, threshList[ith], iW)\n",
    "                GLM_pvalues = addLatLonThTimeDf(model_GLM.pvalues, latSel, lonSel, threshList[ith], iW)\n",
    "                GLM_aic = addLatLonThTimeDf(pd.Series({'aic':model_GLM.aic}), latSel, lonSel, threshList[ith], iW)\n",
    "                lgR_params.update({field:GLM_params})\n",
    "                lgR_pvalues.update({field:GLM_pvalues})\n",
    "                lgR_aic.update({field:GLM_aic})\n",
    "            \n",
    "            GLM_pred = addLatLonThTimeDf(p_pred, latSel, lonSel, threshList[ith], iW)\n",
    "            lgR_pred.update({field:GLM_pred})\n",
    "\n",
    "    lgR_params_list.append(lgR_params)\n",
    "    lgR_pvalues_list.append(lgR_pvalues)\n",
    "    lgR_pred_list.append(lgR_pred)\n",
    "    lgR_aic_list.append(lgR_aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29edcc59-80c4-4fbf-bb5c-31de38ee489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p0_th0': aic          870.985901\n",
       "  lat          -34.000000\n",
       "  lon          148.000000\n",
       "  threshold     50.000000\n",
       "  timescale      2.000000\n",
       "  dtype: float64,\n",
       "  'p0_th1': aic          106.840303\n",
       "  lat          -34.000000\n",
       "  lon          148.000000\n",
       "  threshold    100.000000\n",
       "  timescale      2.000000\n",
       "  dtype: float64,\n",
       "  'p0_th2': nan}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgR_aic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09afaefa-1419-432f-876f-47766b8b3645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fitting logistic regression models to test grid points\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "# model = glm(formula, data, family)\n",
    "\n",
    "out_dir = '/g/data/w97/ad9701/p_prob_analysis/temp_files/'\n",
    "\n",
    "varname = 'PminusEQ' #'P'   # the name of the directory and file\n",
    "vname = 'PminusEQ' #'precip'  # the name of the variable inside the files\n",
    "fname = varname + '_*_SEA_*.nc'\n",
    "\n",
    "# select some thresholds to look at\n",
    "threshList = [50, 100, 150]\n",
    "\n",
    "# select some lat-lons to look at\n",
    "latList = [-34] #, -34, -34, -37, -37, -37]\n",
    "lonList = [148] #, 145, 142, 148, 145, 142]\n",
    "\n",
    "# select some timescales for analysis\n",
    "ts = [2] #, 6, 8, 12]\n",
    "\n",
    "# get the sst predictors\n",
    "sst_dir = '/g/data/w97/ad9701/p_prob_analysis/sst_data/'\n",
    "pNames = ['soi', 'sami', 'dmi', 'nino34_anom', 'nino4_anom']\n",
    "pFiles = ['soi_monthly.nc', 'newsam.1957.2021.nc', 'dmi.had.long.data.nc', 'nino34.long.anom.data.nc', 'nino4.long.anom.data.nc']\n",
    "for p in np.arange(len(pNames)):\n",
    "    ds_temp = xr.open_dataset(sst_dir+pFiles[p])\n",
    "    if (p>0):\n",
    "        ds_p[pNames[p]]=ds_temp[pNames[p]]\n",
    "    else:\n",
    "        ds_p = ds_temp\n",
    "    del ds_temp\n",
    "\n",
    "# select the predictors to include in the model\n",
    "predSel = ['season', 'soi', 'dmi']\n",
    "formula = 'response ~ soi+dmi'\n",
    "    \n",
    "# function to create a new data frame that will be used to 'predict' probabilities from the fitted model\n",
    "# the new data points would cover combinations of unique values for categorical predictors and mean/perturbations one sd above the mean for quantitative predictors\n",
    "import itertools\n",
    "import pandas as pd\n",
    "def createNewDf(df, fields):\n",
    "    '''Function creates a sample dataframe from a larger input dataframe (df).\n",
    "       The sample points will include all permutations of columns specfied (fields).\n",
    "       String columns: use unique values. Numeric columns: Mean, Mean-1SD, Mean+1SD\n",
    "    '''\n",
    "    dataVal = []\n",
    "    for f in fields:\n",
    "        # str data types are assumed to be categorical variables\n",
    "        if (isinstance(df[f][0], str)):\n",
    "            dataVal.append(pd.unique(df[f]))\n",
    "        else:\n",
    "            temp = [df[f].mean()]\n",
    "            temp.extend([df[f].mean()+df[f].std(), df[f].mean()-df[f].std()])\n",
    "            dataVal.append(temp)\n",
    "            del temp\n",
    "    # get all combinations of values across the fields\n",
    "    dataValPermute = list(itertools.product(*dataVal))\n",
    "    # make it into a data frame\n",
    "    newDf = pd.DataFrame(dataValPermute, columns = fields)\n",
    "    return(newDf)\n",
    "\n",
    "def addLatLonTh(mydict, latSel, lonSel, threshSel):\n",
    "    mydict.update({'lat':latSel})\n",
    "    mydict.update({'lon':lonSel})\n",
    "    mydict.update({'threshold':threshSel})\n",
    "    return(mydict)\n",
    "\n",
    "def addLatLonThTimeDf(df, latSel, lonSel, threshSel, tsSel):\n",
    "    df['lat'] = latSel\n",
    "    df['lon'] = lonSel\n",
    "    df['threshold'] = threshSel\n",
    "    df['timescale'] = tsSel\n",
    "    return(df)\n",
    "\n",
    "def addLatLonThTimeSeasDf(df, latSel, lonSel, threshSel, tsSel, seas):\n",
    "    df['lat'] = latSel\n",
    "    df['lon'] = lonSel\n",
    "    df['threshold'] = threshSel\n",
    "    df['timescale'] = tsSel\n",
    "    df['season'] = seas\n",
    "    return(df)\n",
    "\n",
    "lgR_params_list_seas = []\n",
    "lgR_pvalues_list_seas = []\n",
    "lgR_pred_list_seas = []\n",
    "lgR_aic_list_seas = []\n",
    "\n",
    "for iW in ts:\n",
    "    data_dir = '/g/data/w97/ad9701/p_prob_analysis/temp_files/'+varname+'_week'+str(iW)+'/'\n",
    "    ds = xr.open_mfdataset(data_dir + fname, chunks = {'lat':400, 'lon':400})\n",
    "    \n",
    "    # select predictors for the same period as the data\n",
    "    x1 = ds['time.season'].values     # season, this is the first predictor\n",
    "    da_time_bymon = np.array(pd.to_datetime(ds.time).to_period('M').to_timestamp().floor('D'))\n",
    "    ds_p_sel = ds_p.sel(time = da_time_bymon)\n",
    "    xp = []\n",
    "    for p in pNames:\n",
    "        xp.append(ds_p_sel[p].values)\n",
    "    xp_dict = dict(zip(pNames, xp))\n",
    "    xp_dict.update({\"season\": x1})    # add season to the sst predictors    \n",
    "    xp_df = pd.DataFrame(xp_dict)     # make a dataframe of predictors\n",
    "    \n",
    "    # create a new df of sample points at which 'predictions' will be made using the fitted model\n",
    "    newDf = createNewDf(xp_df, predSel)\n",
    "    \n",
    "    lgR_params = {}\n",
    "    lgR_pvalues = {}\n",
    "    lgR_pred = {}\n",
    "    lgR_aic = {}\n",
    "    \n",
    "    for iPt in np.arange(len(latList)):\n",
    "        latSel = latList[iPt]\n",
    "        lonSel = lonList[iPt]\n",
    "        da_pt = ds[vname].sel(lat = latSel, lon = lonSel).load()\n",
    "\n",
    "        for ith in np.arange(len(threshList)):\n",
    "            # create a dataframe of reponse and predictors\n",
    "            y = np.where(da_pt.values>=threshList[ith], 1, 0)\n",
    "            d = {\"response\": y}\n",
    "            d.update(xp_dict)\n",
    "            df = pd.DataFrame(d)\n",
    "\n",
    "            df_seas = df.groupby('season')\n",
    "            newDf_seas = newDf.groupby('season')\n",
    "            for seas in ['DJF', 'MAM', 'JJA', 'SON']:\n",
    "                # field name to save the results\n",
    "                field = 'p' + str(iPt) + '_th' + str(ith) + '_' + seas\n",
    "                \n",
    "                p_pred = newDf_seas.get_group(seas).copy()\n",
    "                if (sum(df_seas.get_group(seas)['response'])<4):\n",
    "                    p_pred['prob'] = 0\n",
    "                    lgR_params.update({field:np.nan})\n",
    "                    lgR_pvalues.update({field:np.nan})  \n",
    "                    lgR_aic.update({field:np.nan})\n",
    "                else:\n",
    "                    # fit the regression model\n",
    "                    model = glm(formula, df_seas.get_group(seas), family=sm.families.Binomial())\n",
    "                    model_GLM = model.fit()\n",
    "                    prob = model_GLM.predict(newDf_seas.get_group(seas))\n",
    "                    p_pred['prob'] = prob\n",
    "            \n",
    "                    # save the results\n",
    "                    GLM_params = addLatLonThTimeSeasDf(model_GLM.params, latSel, lonSel, threshList[ith], iW, seas)\n",
    "                    GLM_pvalues = addLatLonThTimeSeasDf(model_GLM.pvalues, latSel, lonSel, threshList[ith], iW, seas)\n",
    "                    GLM_aic = addLatLonThTimeSeasDf(pd.Series({'aic':model_GLM.aic}), latSel, lonSel, threshList[ith], iW, seas)\n",
    "                    lgR_params.update({field:GLM_params})\n",
    "                    lgR_pvalues.update({field:GLM_pvalues})\n",
    "                    lgR_aic.update({field:GLM_aic})\n",
    "            \n",
    "            GLM_pred = addLatLonThTimeSeasDf(p_pred, latSel, lonSel, threshList[ith], iW, seas)\n",
    "            lgR_pred.update({field:GLM_pred})\n",
    "\n",
    "    lgR_params_list_seas.append(lgR_params)\n",
    "    lgR_pvalues_list_seas.append(lgR_pvalues)\n",
    "    lgR_pred_list_seas.append(lgR_pred)\n",
    "    lgR_aic_list_seas.append(lgR_aic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee646df1-f56b-4b30-84c0-5f4b7f717226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p0_th0_DJF': aic          215.427966\n",
       "  lat               -34.0\n",
       "  lon               148.0\n",
       "  threshold          50.0\n",
       "  timescale           2.0\n",
       "  season              DJF\n",
       "  dtype: object,\n",
       "  'p0_th0_MAM': aic          223.021283\n",
       "  lat               -34.0\n",
       "  lon               148.0\n",
       "  threshold          50.0\n",
       "  timescale           2.0\n",
       "  season              MAM\n",
       "  dtype: object,\n",
       "  'p0_th0_JJA': aic          283.435427\n",
       "  lat               -34.0\n",
       "  lon               148.0\n",
       "  threshold          50.0\n",
       "  timescale           2.0\n",
       "  season              JJA\n",
       "  dtype: object,\n",
       "  'p0_th0_SON': aic          148.308741\n",
       "  lat               -34.0\n",
       "  lon               148.0\n",
       "  threshold          50.0\n",
       "  timescale           2.0\n",
       "  season              SON\n",
       "  dtype: object,\n",
       "  'p0_th1_DJF': aic          72.072618\n",
       "  lat              -34.0\n",
       "  lon              148.0\n",
       "  threshold        100.0\n",
       "  timescale          2.0\n",
       "  season             DJF\n",
       "  dtype: object,\n",
       "  'p0_th1_MAM': nan,\n",
       "  'p0_th1_JJA': nan,\n",
       "  'p0_th1_SON': nan,\n",
       "  'p0_th2_DJF': nan,\n",
       "  'p0_th2_MAM': nan,\n",
       "  'p0_th2_JJA': nan,\n",
       "  'p0_th2_SON': nan}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgR_aic_list_seas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a6c017a-0106-4698-b72e-7013c429e270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p0_th0': aic          870.985901\n",
       "  lat          -34.000000\n",
       "  lon          148.000000\n",
       "  threshold     50.000000\n",
       "  timescale      2.000000\n",
       "  dtype: float64,\n",
       "  'p0_th1': aic          106.840303\n",
       "  lat          -34.000000\n",
       "  lon          148.000000\n",
       "  threshold    100.000000\n",
       "  timescale      2.000000\n",
       "  dtype: float64,\n",
       "  'p0_th2': nan}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgR_aic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "389d1add-ce60-45e8-8fa1-f0f8c308e7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>soi</th>\n",
       "      <th>sami</th>\n",
       "      <th>dmi</th>\n",
       "      <th>nino34_anom</th>\n",
       "      <th>nino4_anom</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>0</td>\n",
       "      <td>-10.4</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.72</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.72</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>JJA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      response   soi  sami    dmi  nino34_anom  nino4_anom season\n",
       "11           0 -12.0   NaN -0.700        -0.64       -0.90    JJA\n",
       "12           0 -12.0   NaN -0.700        -0.64       -0.90    JJA\n",
       "13           0 -12.8   NaN -0.677        -0.22       -0.75    JJA\n",
       "14           0 -12.8   NaN -0.677        -0.22       -0.75    JJA\n",
       "15           0 -12.8   NaN -0.677        -0.22       -0.75    JJA\n",
       "...        ...   ...   ...    ...          ...         ...    ...\n",
       "2830         0 -10.4  2.21  0.719         0.66        0.74    JJA\n",
       "2831         0  -5.6 -2.20  0.693         0.41        0.72    JJA\n",
       "2832         0  -5.6 -2.20  0.693         0.41        0.72    JJA\n",
       "2833         0  -4.4 -2.04  0.548         0.19        0.54    JJA\n",
       "2834         0  -4.4 -2.04  0.548         0.19        0.54    JJA\n",
       "\n",
       "[715 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seas.get_group(seas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90caf3d8-4921-48cb-b508-88782ea82235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJF\n",
      "JJA\n",
      "MAM\n",
      "SON\n"
     ]
    }
   ],
   "source": [
    "for x,y in df.groupby('season'):\n",
    "    print(x)\n",
    "    #print(y)\n",
    "    \n",
    "test = df.groupby('season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "013d5f9b-3c01-4d5a-af70-a15a1c41a5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>soi</th>\n",
       "      <th>sami</th>\n",
       "      <th>dmi</th>\n",
       "      <th>nino34_anom</th>\n",
       "      <th>nino4_anom</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.77</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.88</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.88</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.82</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.82</td>\n",
       "      <td>DJF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      response  soi  sami    dmi  nino34_anom  nino4_anom season\n",
       "0            0  3.2   NaN -0.129        -0.57       -0.64    DJF\n",
       "1            0  3.2   NaN -0.129        -0.57       -0.64    DJF\n",
       "2            0  3.2   NaN -0.129        -0.57       -0.64    DJF\n",
       "3            0  1.6   NaN -0.406        -0.58       -0.47    DJF\n",
       "4            0  1.6   NaN -0.406        -0.58       -0.47    DJF\n",
       "...        ...  ...   ...    ...          ...         ...    ...\n",
       "2843         0 -5.5 -1.78  0.312         0.51        0.77    DJF\n",
       "2844         0  1.3  0.57  0.238         0.64        0.88    DJF\n",
       "2845         0  1.3  0.57  0.238         0.64        0.88    DJF\n",
       "2846         0 -2.2 -0.36  0.134         0.48        0.82    DJF\n",
       "2847         0 -2.2 -0.36  0.134         0.48        0.82    DJF\n",
       "\n",
       "[707 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_group('DJF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f586c6e-89e8-440b-8aaa-d53aaa2a99fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save dataframes for plotting script\n",
    "import pickle\n",
    "# df.to_pickle(file_name)\n",
    "\n",
    "file_pvalues = out_dir + 'lgR_pvalues.pkl'\n",
    "file_params = out_dir + 'lgR_params.pkl'\n",
    "file_pred = out_dir + 'lgR_pred.pkl'\n",
    "\n",
    "import os, errno\n",
    "\n",
    "def silentremove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
    "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
    "            raise # re-raise exception if a different error occurred\n",
    "            \n",
    "silentremove(file_pvalues)\n",
    "silentremove(file_params)\n",
    "silentremove(file_pred)\n",
    "\n",
    "with open(file_pvalues, 'wb') as f:\n",
    "    pickle.dump(lgR_pvalues_list, f)\n",
    "\n",
    "with open(file_params, 'wb') as f:\n",
    "    pickle.dump(lgR_params_list, f)\n",
    "    \n",
    "with open(file_pred, 'wb') as f:\n",
    "    pickle.dump(lgR_pred_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df98063-583c-4b67-81f3-02804e2206d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baeb5cee-898c-43bc-9158-1bb989ecf08d",
   "metadata": {},
   "source": [
    "### Scratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a2b108-03fb-47f4-8a31-f7e8fbf11eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>response</td>     <th>  No. Observations:  </th>  <td>  2854</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  2848</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -47.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 06 Oct 2021</td> <th>  Deviance:          </th> <td>  94.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:35:47</td>     <th>  Pearson chi2:      </th> <td>1.89e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>25</td>        <th>  Pseudo R-squ. (CS):</th> <td>0.005301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   -5.1301</td> <td>    0.514</td> <td>   -9.976</td> <td> 0.000</td> <td>   -6.138</td> <td>   -4.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(season)[T.JJA]</th> <td>  -21.7671</td> <td> 1.28e+04</td> <td>   -0.002</td> <td> 0.999</td> <td> -2.5e+04</td> <td>  2.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(season)[T.MAM]</th> <td>   -1.7773</td> <td>    1.083</td> <td>   -1.641</td> <td> 0.101</td> <td>   -3.900</td> <td>    0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(season)[T.SON]</th> <td>   -1.9030</td> <td>    1.130</td> <td>   -1.684</td> <td> 0.092</td> <td>   -4.118</td> <td>    0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soi</th>              <td>    0.0784</td> <td>    0.039</td> <td>    2.023</td> <td> 0.043</td> <td>    0.002</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dmi</th>              <td>   -0.5834</td> <td>    1.324</td> <td>   -0.441</td> <td> 0.659</td> <td>   -3.178</td> <td>    2.011</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:               response   No. Observations:                 2854\n",
       "Model:                            GLM   Df Residuals:                     2848\n",
       "Model Family:                Binomial   Df Model:                            5\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -47.420\n",
       "Date:                Wed, 06 Oct 2021   Deviance:                       94.840\n",
       "Time:                        14:35:47   Pearson chi2:                 1.89e+03\n",
       "No. Iterations:                    25   Pseudo R-squ. (CS):           0.005301\n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           -5.1301      0.514     -9.976      0.000      -6.138      -4.122\n",
       "C(season)[T.JJA]   -21.7671   1.28e+04     -0.002      0.999    -2.5e+04     2.5e+04\n",
       "C(season)[T.MAM]    -1.7773      1.083     -1.641      0.101      -3.900       0.345\n",
       "C(season)[T.SON]    -1.9030      1.130     -1.684      0.092      -4.118       0.312\n",
       "soi                  0.0784      0.039      2.023      0.043       0.002       0.154\n",
       "dmi                 -0.5834      1.324     -0.441      0.659      -3.178       2.011\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GLM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5bda68d-854f-443b-9c67-458b843264d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.84030251551013"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GLM.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c638138b-c546-40f7-803a-d58eee104a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.29951825e-03,  1.05110584e-03,  1.14702821e-03, -3.36845392e-06,\n",
       "        4.69702544e-01, -4.96852781e-01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = model_GLM.cov_params()\n",
    "np.array(xx)\n",
    "model_GLM.params.values/np.sqrt(np.diagonal(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd75b955-392c-4450-ae7e-d6a3ad1ea5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p0_th0': Intercept            -3.321286\n",
       "  C(season)[T.JJA]      0.306182\n",
       "  C(season)[T.MAM]      0.007289\n",
       "  C(season)[T.SON]     -0.555345\n",
       "  soi                   0.036126\n",
       "  dmi                  -0.236192\n",
       "  lat                 -34.000000\n",
       "  lon                 148.000000\n",
       "  threshold            50.000000\n",
       "  timescale             2.000000\n",
       "  dtype: float64,\n",
       "  'p0_th1': Intercept            -5.088596\n",
       "  C(season)[T.JJA]     -1.758919\n",
       "  C(season)[T.MAM]     -1.766887\n",
       "  C(season)[T.SON]     -1.774395\n",
       "  soi                   0.078037\n",
       "  dmi                  -0.000967\n",
       "  lat                 -34.000000\n",
       "  lon                 148.000000\n",
       "  threshold           100.000000\n",
       "  timescale             2.000000\n",
       "  dtype: float64,\n",
       "  'p0_th2': nan}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgR_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ac85d7d-5aa8-44f5-8f51-65cbcf56999a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p0_th0': Intercept           1.884585e-61\n",
       "  C(season)[T.JJA]    2.459467e-01\n",
       "  C(season)[T.MAM]    9.791027e-01\n",
       "  C(season)[T.SON]    8.710569e-02\n",
       "  soi                 4.181794e-04\n",
       "  dmi                 4.597139e-01\n",
       "  lat                -3.400000e+01\n",
       "  lon                 1.480000e+02\n",
       "  threshold           5.000000e+01\n",
       "  timescale           2.000000e+00\n",
       "  dtype: float64,\n",
       "  'p0_th1': Intercept           4.443611e-25\n",
       "  C(season)[T.JJA]    1.091294e-01\n",
       "  C(season)[T.MAM]    1.026427e-01\n",
       "  C(season)[T.SON]    1.092167e-01\n",
       "  soi                 2.810192e-02\n",
       "  dmi                 9.993581e-01\n",
       "  lat                -3.400000e+01\n",
       "  lon                 1.480000e+02\n",
       "  threshold           1.000000e+02\n",
       "  timescale           2.000000e+00\n",
       "  dtype: float64,\n",
       "  'p0_th2': nan}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgR_pvalues_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d17b958e-ab4a-486a-8e1c-b965f59fe55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p0_th0':    season        soi       dmi      prob  lat  lon  threshold  timescale\n",
       "  0     DJF  -0.083532 -0.087893  0.035450  -34  148         50          2\n",
       "  1     DJF  -0.083532  0.249232  0.032826  -34  148         50          2\n",
       "  2     DJF  -0.083532 -0.425019  0.038276  -34  148         50          2\n",
       "  3     DJF   9.944699 -0.087893  0.050151  -34  148         50          2\n",
       "  4     DJF   9.944699  0.249232  0.046491  -34  148         50          2\n",
       "  5     DJF   9.944699 -0.425019  0.054083  -34  148         50          2\n",
       "  6     DJF -10.111762 -0.087893  0.024945  -34  148         50          2\n",
       "  7     DJF -10.111762  0.249232  0.023080  -34  148         50          2\n",
       "  8     DJF -10.111762 -0.425019  0.026957  -34  148         50          2\n",
       "  9     MAM  -0.083532 -0.087893  0.035700  -34  148         50          2\n",
       "  10    MAM  -0.083532  0.249232  0.033058  -34  148         50          2\n",
       "  11    MAM  -0.083532 -0.425019  0.038545  -34  148         50          2\n",
       "  12    MAM   9.944699 -0.087893  0.050499  -34  148         50          2\n",
       "  13    MAM   9.944699  0.249232  0.046815  -34  148         50          2\n",
       "  14    MAM   9.944699 -0.425019  0.054457  -34  148         50          2\n",
       "  15    MAM -10.111762 -0.087893  0.025123  -34  148         50          2\n",
       "  16    MAM -10.111762  0.249232  0.023245  -34  148         50          2\n",
       "  17    MAM -10.111762 -0.425019  0.027149  -34  148         50          2\n",
       "  18    JJA  -0.083532 -0.087893  0.047545  -34  148         50          2\n",
       "  19    JJA  -0.083532  0.249232  0.044067  -34  148         50          2\n",
       "  20    JJA  -0.083532 -0.425019  0.051284  -34  148         50          2\n",
       "  21    JJA   9.944699 -0.087893  0.066915  -34  148         50          2\n",
       "  22    JJA   9.944699  0.249232  0.062111  -34  148         50          2\n",
       "  23    JJA   9.944699 -0.425019  0.072061  -34  148         50          2\n",
       "  24    JJA -10.111762 -0.087893  0.033581  -34  148         50          2\n",
       "  25    JJA -10.111762  0.249232  0.031091  -34  148         50          2\n",
       "  26    JJA -10.111762 -0.425019  0.036263  -34  148         50          2\n",
       "  27    SON  -0.083532 -0.087893  0.020656  -34  148         50          2\n",
       "  28    SON  -0.083532  0.249232  0.019105  -34  148         50          2\n",
       "  29    SON  -0.083532 -0.425019  0.022330  -34  148         50          2\n",
       "  30    SON   9.944699 -0.087893  0.029409  -34  148         50          2\n",
       "  31    SON   9.944699  0.249232  0.027219  -34  148         50          2\n",
       "  32    SON   9.944699 -0.425019  0.031769  -34  148         50          2\n",
       "  33    SON -10.111762 -0.087893  0.014469  -34  148         50          2\n",
       "  34    SON -10.111762  0.249232  0.013376  -34  148         50          2\n",
       "  35    SON -10.111762 -0.425019  0.015650  -34  148         50          2,\n",
       "  'p0_th1':    season        soi       dmi      prob  lat  lon  threshold  timescale\n",
       "  0     DJF  -0.083532 -0.087893  0.006090  -34  148        100          2\n",
       "  1     DJF  -0.083532  0.249232  0.006088  -34  148        100          2\n",
       "  2     DJF  -0.083532 -0.425019  0.006092  -34  148        100          2\n",
       "  3     DJF   9.944699 -0.087893  0.013223  -34  148        100          2\n",
       "  4     DJF   9.944699  0.249232  0.013219  -34  148        100          2\n",
       "  5     DJF   9.944699 -0.425019  0.013228  -34  148        100          2\n",
       "  6     DJF -10.111762 -0.087893  0.002794  -34  148        100          2\n",
       "  7     DJF -10.111762  0.249232  0.002793  -34  148        100          2\n",
       "  8     DJF -10.111762 -0.425019  0.002795  -34  148        100          2\n",
       "  9     MAM  -0.083532 -0.087893  0.001046  -34  148        100          2\n",
       "  10    MAM  -0.083532  0.249232  0.001045  -34  148        100          2\n",
       "  11    MAM  -0.083532 -0.425019  0.001046  -34  148        100          2\n",
       "  12    MAM   9.944699 -0.087893  0.002284  -34  148        100          2\n",
       "  13    MAM   9.944699  0.249232  0.002284  -34  148        100          2\n",
       "  14    MAM   9.944699 -0.425019  0.002285  -34  148        100          2\n",
       "  15    MAM -10.111762 -0.087893  0.000478  -34  148        100          2\n",
       "  16    MAM -10.111762  0.249232  0.000478  -34  148        100          2\n",
       "  17    MAM -10.111762 -0.425019  0.000479  -34  148        100          2\n",
       "  18    JJA  -0.083532 -0.087893  0.001054  -34  148        100          2\n",
       "  19    JJA  -0.083532  0.249232  0.001054  -34  148        100          2\n",
       "  20    JJA  -0.083532 -0.425019  0.001055  -34  148        100          2\n",
       "  21    JJA   9.944699 -0.087893  0.002303  -34  148        100          2\n",
       "  22    JJA   9.944699  0.249232  0.002302  -34  148        100          2\n",
       "  23    JJA   9.944699 -0.425019  0.002303  -34  148        100          2\n",
       "  24    JJA -10.111762 -0.087893  0.000482  -34  148        100          2\n",
       "  25    JJA -10.111762  0.249232  0.000482  -34  148        100          2\n",
       "  26    JJA -10.111762 -0.425019  0.000482  -34  148        100          2\n",
       "  27    SON  -0.083532 -0.087893  0.001038  -34  148        100          2\n",
       "  28    SON  -0.083532  0.249232  0.001038  -34  148        100          2\n",
       "  29    SON  -0.083532 -0.425019  0.001038  -34  148        100          2\n",
       "  30    SON   9.944699 -0.087893  0.002267  -34  148        100          2\n",
       "  31    SON   9.944699  0.249232  0.002267  -34  148        100          2\n",
       "  32    SON   9.944699 -0.425019  0.002268  -34  148        100          2\n",
       "  33    SON -10.111762 -0.087893  0.000475  -34  148        100          2\n",
       "  34    SON -10.111762  0.249232  0.000475  -34  148        100          2\n",
       "  35    SON -10.111762 -0.425019  0.000475  -34  148        100          2,\n",
       "  'p0_th2':    season        soi       dmi  prob  lat  lon  threshold  timescale\n",
       "  0     DJF  -0.083532 -0.087893     0  -34  148        150          2\n",
       "  1     DJF  -0.083532  0.249232     0  -34  148        150          2\n",
       "  2     DJF  -0.083532 -0.425019     0  -34  148        150          2\n",
       "  3     DJF   9.944699 -0.087893     0  -34  148        150          2\n",
       "  4     DJF   9.944699  0.249232     0  -34  148        150          2\n",
       "  5     DJF   9.944699 -0.425019     0  -34  148        150          2\n",
       "  6     DJF -10.111762 -0.087893     0  -34  148        150          2\n",
       "  7     DJF -10.111762  0.249232     0  -34  148        150          2\n",
       "  8     DJF -10.111762 -0.425019     0  -34  148        150          2\n",
       "  9     MAM  -0.083532 -0.087893     0  -34  148        150          2\n",
       "  10    MAM  -0.083532  0.249232     0  -34  148        150          2\n",
       "  11    MAM  -0.083532 -0.425019     0  -34  148        150          2\n",
       "  12    MAM   9.944699 -0.087893     0  -34  148        150          2\n",
       "  13    MAM   9.944699  0.249232     0  -34  148        150          2\n",
       "  14    MAM   9.944699 -0.425019     0  -34  148        150          2\n",
       "  15    MAM -10.111762 -0.087893     0  -34  148        150          2\n",
       "  16    MAM -10.111762  0.249232     0  -34  148        150          2\n",
       "  17    MAM -10.111762 -0.425019     0  -34  148        150          2\n",
       "  18    JJA  -0.083532 -0.087893     0  -34  148        150          2\n",
       "  19    JJA  -0.083532  0.249232     0  -34  148        150          2\n",
       "  20    JJA  -0.083532 -0.425019     0  -34  148        150          2\n",
       "  21    JJA   9.944699 -0.087893     0  -34  148        150          2\n",
       "  22    JJA   9.944699  0.249232     0  -34  148        150          2\n",
       "  23    JJA   9.944699 -0.425019     0  -34  148        150          2\n",
       "  24    JJA -10.111762 -0.087893     0  -34  148        150          2\n",
       "  25    JJA -10.111762  0.249232     0  -34  148        150          2\n",
       "  26    JJA -10.111762 -0.425019     0  -34  148        150          2\n",
       "  27    SON  -0.083532 -0.087893     0  -34  148        150          2\n",
       "  28    SON  -0.083532  0.249232     0  -34  148        150          2\n",
       "  29    SON  -0.083532 -0.425019     0  -34  148        150          2\n",
       "  30    SON   9.944699 -0.087893     0  -34  148        150          2\n",
       "  31    SON   9.944699  0.249232     0  -34  148        150          2\n",
       "  32    SON   9.944699 -0.425019     0  -34  148        150          2\n",
       "  33    SON -10.111762 -0.087893     0  -34  148        150          2\n",
       "  34    SON -10.111762  0.249232     0  -34  148        150          2\n",
       "  35    SON -10.111762 -0.425019     0  -34  148        150          2}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgR_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a043b8-2ce1-4d88-a292-ec81c8b5aba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-21.07]",
   "language": "python",
   "name": "conda-env-analysis3-21.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
